{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7971fb0",
   "metadata": {},
   "source": [
    "# Preprocessing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56e37b",
   "metadata": {},
   "source": [
    "corpus de test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "977c8860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a.tekiouk\\AppData\\Local\\Temp\\ipykernel_62504\\735203815.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  corpus_sephora3k = pd.read_csv(\"C:/Users/a.tekiouk/Sujet_2/Sujet_2/DATA/corpus_sephora3k.csv\",sep=\";\", error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus_sephora3k = pd.read_csv(\"C:/Users/a.tekiouk/Sujet_2/Sujet_2/DATA/corpus_sephora3k.csv\",sep=\";\", error_bad_lines=False)\n",
    "corpus_sephora3k.head()\n",
    "text = corpus_sephora3k[corpus_sephora3k['language'] == 'en']['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d100cfe",
   "metadata": {},
   "source": [
    "#### Identification des doublons\n",
    "Afin d'éviter d'analyser le texte de post identiques, nous allons ici supprimer les doublons présent dans notre corpus de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cc3d5",
   "metadata": {},
   "source": [
    "Pour ce faire nous allon utiliser la librairie textdistance (`pip install text-distance`), et nottament la distance normalisée `textdistance.hamming.normalized_distance` qui nous permettra de définir un seuil entre 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "15544dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e211ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = textdistance.hamming.normalized_distance #initialisiation de hamming avec la distance normalisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea61527",
   "metadata": {},
   "source": [
    "On doit enlever les hashtags temporairement afin de vérifier s'il existe des doublons, car en effet des hashtag différent sur deux posts qui sont en fait identiques peuvent perturber le tri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea7e57",
   "metadata": {},
   "source": [
    "Fonction permettant de créer une copy de notre corpus de texte, sans les hashtags : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a33b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_hashtag(t): #--text\n",
    "    txt = text.copy()\n",
    "    for i in range(len(txt)):\n",
    "        txt[i] = re.sub(\"#[A-Za-z0-9_]+\",\"\", txt[i]) #On supprime tout les types de #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f6fa5a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming(' a a a Je joue foot','Je joue foot a a a')\n",
    "#Compare mot à mot la chaine de caractère ?\n",
    "#hamming(text[7],'The tea is HOT! Did you know that these 4 big beauty companies own the vast majority of beauty sales? Were you shocked to see that some of your favorite brands are owned by the same companies?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f309c",
   "metadata": {},
   "source": [
    "Une fois les hashtags retiré, il nous faut calculer la distance entre tout les éléments du corpus. La fonction suivante va calculer la distance entre les élements de la liste (corpus de texte) et ensuite supprimer les élements qui sont présent plusieurs fois :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00d60ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ Renvoie une matrice de distance, pas opti\n",
    "#------------------------------------------------------------------------------------------\n",
    "def dist_mat(t): #-- text\n",
    "    dist_matrix = np.zeros((len(t),len(t)),dtype=np.float)\n",
    "    for i in range(len(t)):\n",
    "        for j in range(len(t)):\n",
    "            dist_matrix[i,j] = hamming(t[i],t[j])\n",
    "    return dist_matrix\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def del_double(t,s): # --text --seuil (s dans [0;1], deux textes identiques ont une distance de 0)\n",
    "    i = 0\n",
    "    r = len(t)\n",
    "    while(i<r):\n",
    "        r = len(t)\n",
    "        j=i+1\n",
    "        while(j<r):\n",
    "            if(hamming(t[i],t[j]) <= s ): # Si la distance entre les deux élemens de la liste inf à seuil\n",
    "                del t[j] #delete\n",
    "                r = len(t) #on actualise la taille de la listes\n",
    "            else:\n",
    "                j+=1\n",
    "        i+=1\n",
    "    return t\n",
    "\n",
    "# Rajouter le texte d'origine(avec les #) et supprimez dans les deux listes, pas opti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbb645",
   "metadata": {},
   "source": [
    "Suppression des posts identifiés comme doublons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8bab4b15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984\n"
     ]
    }
   ],
   "source": [
    "del_double(txt,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45a006b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735\n"
     ]
    }
   ],
   "source": [
    "print(len(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a35428",
   "metadata": {},
   "source": [
    "#### Ratio mot/hashtag\n",
    "Calcul du ratio mot/hastag dans un post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b42db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab3b69",
   "metadata": {},
   "source": [
    "(OPTIONEL) Ici nous ajoutons le token 'hashtag' dans la pipe du modèle spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6a638b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.hashtag_pipe(doc)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  /!\\ Ne marche pas\n",
    "#--------------------------------------------------------------------------------------------\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"hashtag\")\n",
    "def hashtag_pipe(doc):\n",
    "    merged_hashtag = False\n",
    "    while True:\n",
    "        for token_index,token in enumerate(doc):\n",
    "            if token.text == '#':\n",
    "                if token.head is not None:\n",
    "                    start_index = token.idx\n",
    "                    end_index = start_index + len(token.head.text) + 1\n",
    "                    print(start_index, end_index)\n",
    "                    with doc.retokenize() as retokenizer:\n",
    "                        if retokenizer.merge(doc[start_index:end_index]) is not None:\n",
    "                            merged_hashtag = True\n",
    "                            break\n",
    "        if not merged_hashtag:\n",
    "            break\n",
    "        merged_hashtag = False\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"hashtag\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ab37d",
   "metadata": {},
   "source": [
    "Afin de calculer le ration mo/hashtags, nous allons claculer le nombre de mot, cependant en utilisant la pipe spacy classique, un '#' est un token en lui-même. Nous devons donc calculer le nom de de '#' et le soustraire au nombre total de mot, car en effet tout les mot précédé d'un '#' seront considéré comme de \"vrai' mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e251298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "def del_junk_post(t,s): # --text --seuil (s dans [0;1], le seuil 1 permet de supprimer un post composé à 100% de hashtag)\n",
    "    nlp = English()\n",
    "    i = 0\n",
    "    r = len(t)\n",
    "    while(i<r):\n",
    "        r = len(t)\n",
    "        print(i)\n",
    "        nb_hash = 0\n",
    "        nb_word = 0\n",
    "        doc = nlp(t[i]) # On tokenize l'element de notre liste\n",
    "        for token in doc: # Pour chaque token de la liste\n",
    "            if(token.text == '#'):\n",
    "                nb_hash+=1\n",
    "            else:\n",
    "                nb_word+=1\n",
    "        print('nb hash : \\f', nb_hash)\n",
    "        print('nb word : \\f', nb_word)\n",
    "        if(nb_word-nb_hash==0): # On vérifie d'abord que le nombre de mot n'est pas nul, auquel cas nous supprimmons le post\n",
    "            del t[i]\n",
    "            r = len(t)\n",
    "        elif(nb_hash/(nb_word-nb_hash) > s): # On calcul le ratio, si inférieur au seuil => on delete\n",
    "            del t[i]\n",
    "            r = len(t)\n",
    "        i+=1\n",
    "    return t\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5bbb3175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bonjour à tous', 'Salut']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = ['a #salut #bonjour #hello', 'Bonjour à tous','je je je je #salut #bonjour #hello','Salut']\n",
    "del_junk_post(tst,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90adae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bjr  #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj #dsojkncdsj0ncdsj #dsojkncdsjncdsj #dsojkncdsjncdsj', 'Bjr']\n"
     ]
    }
   ],
   "source": [
    "print(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d602d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4778179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4d16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74223bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5de2737",
   "metadata": {},
   "source": [
    "Suppression des post ayant un ratio mot/hashtag trop faible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ad791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7edf812b",
   "metadata": {},
   "source": [
    "#### Fréquence d'apparition dans la langue anglaise\n",
    "Fréquence d'apparition de chaque mot du post dans la langue anglaise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f0b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e107723",
   "metadata": {},
   "source": [
    "check les seuils , décomposer les mot dans les hashtag, position du hashtag dans le post, dictionnaire frequence langue anglaise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1fa42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e48141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22861e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c4063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8960de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0a77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59535933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61459d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508540cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6e936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82bda77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20096786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe47b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e6a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa9b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d04cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49212a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9e2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
